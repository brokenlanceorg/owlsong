<html>

	<head>
		<title>
		The Abstract Shire : Dedication to Logic : Mathematics : Physics
		</title>

	<link rel=StyleSheet href="../Declarations.css" type="text/css">

	</head>

<body>

	<body bgcolor=black>

      <center><img src="../Physics.jpg"></center>
      <img src="../graybar2.gif" width=100% height=9px>

      <center>
      <table cellpadding=20 cellspacing=10 width=90%>
      <tr> 
      <td bgcolor=#222222 valign=top width=50%>
      <div class=bodyWhiteSmallJustify>
         <p>
The modern form of the neural network is usually attributed to several individuals and groups among which we find, 
Paul Webos, LeCun, Parker, Rumelhart et. al., and the Parallel Distributed Processing (PDP) group, among many others. 
This modern form consists of layers of neurons which are interconnected in various ways. Each neuron computes a weighted 
sum of its inputs, and applies a sigmoid activation function to that sum to obtain an output value which gets transmitted down 
its axon to the neurons in the next layer. Based on how close the output is to the proper output, the network then modifies 
the weights on the connections between the neuron layers, and starts the process over again.
         </p>
         <p>
Unfortunately, there is no neural network analogue to the perceptron convergence theorem; moreover, it has been shown that the 
algorithms in neural networks, in consequence of the continuity of the sigmoid functions, can suffer ill-affects from local minima 
in the search space. These overestimated results nearly extirpated research during the 1960’s and 1970’s, however, due 
to the computational power of today’s computers, connectionism, i.e., neural network based artificial intelligence, 
has experienced phenomenal growth in research, programs, and research grants.
         </p>
         <p>
         </p>
         <p>
         </p>
         <p>
         </p>
         <p>
         </p>
         <p>
         </p>
      </div>
      </td>

	<td bgcolor=#222222 valign=top width=50%>
      <div class=bodyWhiteSmallJustify>
         <p>
In this paper, attention will be placed primarily on the layered, feed-forward, fully-connected networks that are also known as backward 
propagation networks (backprop nets). In consequences of heightened research interest in this field, there are indeed a 
plethora of network models. Such models include Hopfield networks, Jordan networks, Boltzmann machines, and many others.
         </p>
         <p>
The Hopfield network was introduced in the paper “Neural Networks and Physical Systems With Emergent Collective Computational 
Abilities” in 1982 by the Caltech physicist, John Hopfield. These networks were based on the neuroscientists’ theories on memory, 
and the physicists’ spin glasses. The neurons are not arranged hierarchically as the typical neural network, but the basic structure is 
similar, that is to say, the neurons can send and receive impulse signals across weighted virtual connections. Each neuron may 
output either +1 or -1, and all neurons are connected to their neighbors by symmetric weighted connections. If the connection 
is positive, then the two neurons tend to inhibit each other. 
         </p>
         <p>
         </p>
       </div>
       </td>
       </tr>
       </table>
       </center>


      <center>
	<table cellpadding=0 cellspacing=10 width=100%>
      <tr>
      <td>
         <div align=left>
         <a href="BWNeural7.htm" target="Main"><img src="../previous.gif" border=no></a>
         </div>
      </td>
      <td> 
      <center>
         <span class=linkTextWhite>[</span>
         <a href="../BWMain.htm" target="Main"><span class=linkTextWhite>Home</span></a>
         <span class=linkTextWhite>|</span>
         <a href="../BWMathematics.htm" target="Main"><span class=linkTextWhite>Mathematics</span></a>
         <span class=linkTextWhite>|</span>
         <a href="../BWPhysics.htm" target="Main"><span class=linkTextWhite>Physics</span></a>
         <span class=linkTextWhite>|</span>
         <a href="../BWPhilosophy.htm" target="Main"><span class=linkTextWhite>Philosophy</span></a>
         <span class=linkTextWhite>]</span>
      </center>
      </td>

      <td>
         <div align=right>
         <a href="BWNeural9.htm" target="Main"><img src="../next.gif" border=no></a>
         </div>
      </td>

      </tr>

      <tr>
      <td>
      </td>
      <td>
      <span class=footnoteRedSmall>
         <center>
         Design and Content by Brandon Benham<br>
         <a href="mailto:brandbn@attglobal.net"><img src="../mailto4.gif" border=no></a>
         </center>
      </span>
      </td>
      </tr>
      </table>
      </center>

</body>


</html>
<!--             <span class="symbol1"><span class="symbol2">m</span></span> -->